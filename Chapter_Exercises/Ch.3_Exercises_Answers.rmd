---
title: "Ch.2_Exercises"
author: "Patrick Edwards"
date: '2022-06-02'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Code for easy problems.
```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 )

prior <- rep( 1 , 1000 )

likelihood <- dbinom( 6 , size=9 , prob=p_grid )

posterior <- likelihood * prior

posterior <- posterior / sum(posterior)

set.seed(100)

samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
```


# 3E1. how much posterior probability lies below $p = 0.2$?

```{r}
sum(samples < 0.2)/1e4
#0.004, or 0.4%
```

# 3E2. how much posterior probability lies above $p = 0.8$?
```{r}
mean(samples > 0.8)
# 0.1116, or 11.16%
```


# 3E3. How much posterior probability lies betweenan $p = 0.2$ and $0.8$?
```{r}
mean(samples > 0.2 & samples < 0.8)
# 0.888, or 88.8%
```


# 3E4. 20% of the posterior probability lies below which value of p?

```{r}
quantile(samples, 0.2)
# p = 0.5185
```


# 3E5. 20% of the posterior probability lies above which value of p?
```{r}
quantile(samples, 0.8)
# p = 0.7557558 
```


# 3E6. Which values of p contain the narrowest interval equal to 66% of the posterior probability?
```{r}
rethinking::HPDI(samples, prob = 0.66)
#(0.5085085, 0.7737738)
```


# 3E7. Which values of p contain 66% of the posterior probability, assuming equal posterior probability both below and above the interval?
```{r}
rethinking::PI(samples, prob = 0.66)
# (0.5025025, 0.7697698)
```


# 3M1. Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.
```{r}
# Create probability grid:
p_grid <- seq(
  from = 0,
  to = 1, 
  length.out = 1e4
)

# Uniform prior:
prior <- rep( 1 , 1e4)

# Create likelihood from dbinom with 8 successes in 15 trials:
likelihood <- dbinom(8, 15, prob = p_grid)

# Find posterior:
posterior <- likelihood*prior

# standardize posterior:
posterior <- posterior/sum(posterior)

# Plot posterior:
plot(
  p_grid, 
  posterior, 
  type = "b",
  xlab = "probability of water", 
  ylab = "posterior probability"
)
mtext("10,000 points")
```


# 3M2. Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p.

```{r}
# Sample from posterior in previous problem:
samples <- sample(
  p_grid, 
  prob = posterior,
  size = 1e4,
  replace = TRUE
)

rethinking::HPDI(samples, prob = 0.90)
# (0.3367337, 0.7271727)
```


# 3M3. Construct a posterior predictive check for this model and data. The means simulate the distribution of samples, averaging over the posterior uncertainty in p. What is the probability of observing 8 water in 15 tosses?

GOAL: find the **posterior predictive distribution**. This means carrying the uncertainty forward by simulating samples from the model's actual posterior distribution.

```{r}
# Generate posterior predictive distribution:
w <- rbinom(
  1e4,
  size = 15,
  prob = samples
)

# Plot to see what it looks like:
rethinking::simplehist(w)
# Looks correct

# Recall that the posterior predictive distribution contains 10,000 samples. So, divide each value of the distribution by 10,000 to find the proportion of all samples corresponding to 8 waters out of 15 tosses.

table(w)/1e4
# 14.76% is the probability of observing eight waters out of 15 tosses.
```


# 3M4. Using the posterior distribution constructed from the new (8/15) data, now calculate the probability of observing 6 water in 9 tosses.

```{r}
# Generate new posterior predictive distribution for 9 tosses:
w2 <- rbinom(
  1e4,
  size = 9,
  prob = samples
)

# Plot for looks:
rethinking::simplehist(w2)

table(w2)/1e4

# 18.11% is the probability of observing 6 waters in 9 tosses.
```


# 3M5. Start over at 3M1, but now use a prior that is zero below $p = 0.5$ and a constant above $p = 0.5$. This corresponds to prior information that a majority of the Earth’s surface is water. Repeat each problem above and compare the inferences. What difference does the better prior make? If it helps, compare inferences (using both priors) to the true value $p = 0.7$.

```{r}
# Redo other parts of 3m1:
# Create probability grid:
p_grid2 <- seq(
  from = 0,
  to = 1, 
  length.out = 1e4
)

# New prior:
prior2 <- ifelse(
  p_grid2 < 0.5,
  yes = 0,
  no = 1
)

# Repeat rest of 3m1:
likelihood2 <- dbinom(8, 15, prob = p_grid2)
posterior2 <- likelihood2*prior2
posterior2 <- posterior2/sum(posterior2)

## Compare original vs. new plots:
plot(
  p_grid, 
  posterior, 
  type = "b",
  xlab = "probability of water", 
  ylab = "posterior probability"
)
mtext("Old Prior")
plot(
  p_grid2, 
  posterior2, 
  type = "b",
  xlab = "probability of water", 
  ylab = "posterior probability"
)
mtext("New Prior")


# Repeat 3m2: 
samples2 <- sample(
  p_grid2, 
  prob = posterior2,
  size = 1e4,
  replace = TRUE
)

## Compare old vs. new HPDI:
rethinking::HPDI(samples, prob = 0.90)
rethinking::HPDI(samples2, prob = 0.90)
# New HPDI is narrower, suggesting an improvement in precision.

# Repeat 3m3: 
w_2 <- rbinom(
  1e4,
  size = 15,
  prob = samples2
)
## Compare old vs. new histogram:
rethinking::simplehist(w)
rethinking::simplehist(w_2)
# Second one is taller at its peak, suggesting improvements in probability.

## Compare old vs. new table:
table(w)/1e4
table(w_2)/1e4


# Repeat 3m4: 
w2_2 <- rbinom(
  1e4,
  size = 9,
  prob = samples2
)

## Compare old vs. new histogram:
rethinking::simplehist(w2)
rethinking::simplehist(w2_2)

## Compare old vs. new table:
table(w2)/1e4
table(w2_2)/1e4
```

Overall, the new priors seem to increase precision of our inferences around the true value p = 0.7. It does this by strongly reducing our likelihood of seeing fewer than 1/2 of our tosses being water.

# 3M6. Suppose you want to estimate the Earth’s proportion of water very precisely. Specifically, you want the 99% percentile interval of the posterior distribution of p to be only 0.05 wide. This means the distance between the upper and lower bound of the interval should be 0.05. How many times will you have to toss the globe to do this?